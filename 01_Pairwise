{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to process by pandas [id, sequence, collected date, species(panglin lineages)]\n",
    "def create_dataframe_from_fasta(fasta_input_data:str):\n",
    "  fasta_lists = [\n",
    "    [\n",
    "      record.id, #id\n",
    "      str(record.seq), # amino acid sequence\n",
    "      record.description.split('|')[2], # collected date\n",
    "      record.description.split('|')[1] # species(pangolin lineages)\n",
    "    ]\n",
    "    for record in tqdm(SeqIO.parse(fasta_input_data, 'fasta'))\n",
    "    ]\n",
    "  return pd.DataFrame(fasta_lists, columns = ['id', 'sequence', 'date', 'pangolin'])\n",
    "\n",
    "df = create_dataframe_from_fasta(os.path.join('Input_fasta', '2022-06-07_sequences.fasta')) # decompress from 7z file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_unnecessary_seq(df):\n",
    "    unknown_seq_exclude = df['sequence'].str.match('^(?!.*(X|B|J|Z)).*$') # Create a filter that excludes the unwanted sequences.\n",
    "    df = df[unknown_seq_exclude] # Exclude the unwanted sequences.\n",
    "    df = df.drop_duplicates(subset = ['sequence'])\n",
    "    return df\n",
    "\n",
    "df = exclude_unnecessary_seq(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pairwise_wuhan_spike_sequence(df):\n",
    "    flatten = lambda target_list: [\n",
    "        item for sublist in target_list\n",
    "        for item in (flatten(sublist) if hasattr(sublist, '__iter__') and not isinstance(sublist, str) else (sublist,))\n",
    "        ] # Def flatten, make the nested list flatten.\n",
    "    \n",
    "    wuhan_spike_seq =\\\n",
    "        'MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIF'\\\n",
    "        'GTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINL'\\\n",
    "        'VRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNF'\\\n",
    "        'RVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYK'\\\n",
    "        'LPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKS'\\\n",
    "        'TNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVY'\\\n",
    "        'STGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPRRARSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYI'\\\n",
    "        'CGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARD'\\\n",
    "        'LICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQ'\\\n",
    "        'NAQALNTLVKQLSSNFGAISSVLNDILSRLDKVEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGV'\\\n",
    "        'VFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDL'\\\n",
    "        'GDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKWPWYIWLGFIAGLIAIVMVTIMLCCMTSCCSCLKGCCSCGSCCKFDEDDSEPVLKGVKLHYT'\n",
    "    pairwise_result = [pairwise2.align.localms(wuhan_spike_seq, i, 2, -1, -10, -.1) for i in tqdm(df['sequence'])]\n",
    "    return pairwise_result\n",
    "\n",
    "# It takes a lot of time (over 10 h in my environment).\n",
    "pairwise_result = Pairwise_wuhan_spike_sequence(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns and drop rows that sequence length are not 1273.\n",
    "df['pairwised_sequence'], df['pairwised_length'] = [sublist[0][1] for sublist in tqdm(pairwise_result)], [sublist[0][4] for sublist in tqdm(pairwise_result)]\n",
    "df_result = df.query('pairwised_length == 1273')\n",
    "\n",
    "df_result.to_csv(os.path.join('Results', 'Pairwised_Results.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutants and their variants\n",
    "species_vum = {'AZ.5','C.1.2','B.1.640'} # VUM: Variant under Monitoring\n",
    "\n",
    "def assign_species_from_pangolin(x:str): # https://www.cdc.gov/coronavirus/2019-ncov/variants/variant-classifications.html?CDC_AA_refVal=https%3A%2F%2Fwww.cdc.gov%2Fcoronavirus%2F2019-ncov%2Fvariants%2Fvariant-info.html\n",
    "    if x == 'B.1.1.7' or x.startswith('Q') :\n",
    "        return 'Alpha'\n",
    "    \n",
    "    elif x.startswith('B.1.351'):\n",
    "        return 'Beta'\n",
    "    \n",
    "    elif x.startswith('P.1') :\n",
    "        return 'Gamma'\n",
    "    \n",
    "    elif x == 'B.1.617.2' or x.startswith('AY') :\n",
    "        return 'Delta'\n",
    "    \n",
    "    elif x == \"B.1.427\" or x == \"B.1.429\":\n",
    "        return \"Epsilon\"\n",
    "    \n",
    "    elif x == \"B.1.525\":\n",
    "        return \"Eta\"\n",
    "    \n",
    "    elif x == \"B.1.617.1\":\n",
    "        return \"Kappa\"\n",
    "    \n",
    "    elif x == \"B.1.526\":\n",
    "        return \"Iota\"\n",
    "    \n",
    "    elif x == 'B.1.1.529' or x.startswith('BA'):\n",
    "        return 'Omicron'\n",
    "    \n",
    "    elif x.startswith('C.') and x != 'C.1.2':\n",
    "        return 'Lambda'\n",
    "    \n",
    "    elif x.startswith('B.1.6') and x != 'B.1.640' :\n",
    "        return 'Mu'\n",
    "    \n",
    "    elif x == \"P.2\":\n",
    "        return \"Zeta\"\n",
    "    \n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "df_result['species_name'] = [assign_species_from_pangolin(i) for i in tqdm(df_result['pangolin'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Results\", exist_ok = True)\n",
    "df_result.to_csv(os.path.join('Results', 'Pairwised_sequences.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57076f98cea3432ee277415ac0c2ba70c0a8f34def55cae0caa141641e820b11"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
